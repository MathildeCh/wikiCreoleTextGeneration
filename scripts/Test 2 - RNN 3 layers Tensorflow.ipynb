{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c35fe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-27 18:05:30.350696: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-27 18:05:30.673265: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-27 18:05:30.673286: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-27 18:05:32.018679: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-27 18:05:32.018957: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-27 18:05:32.018968: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73c22442",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"../Project/WikiCreole_Texts/Toscane.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a78bf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 50479 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd91c197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{Voir homonymes|Toscane (homonymie)}}\n",
      "{{coord|43.5|11.2|format=dec|region:IT-52_type:landmark_scale:400000|display=title}}\n",
      "{{Infobox Région d'Italie\n",
      " | nom             = Toscane\n",
      " | blason          = Coat of arms of Tuscany.svg\n",
      " | drapeau         = F\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b390979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4378b3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-27 18:05:33.803168: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-27 18:05:33.803390: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-27 18:05:33.803411: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (diego-Inspiron-5370): /proc/driver/nvidia/version does not exist\n",
      "2022-12-27 18:05:33.803659: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc02e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f11a429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[62, 63, 64, 65, 66, 67, 68], [85, 86, 87]]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b409fc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "658a3bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back to string\n",
    "\n",
    "tf.strings.reduce_join(chars, axis=-1).numpy()\n",
    "\n",
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4cc86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c0452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a7e7f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50479,), dtype=int64, numpy=array([88, 88, 54, ..., 60,  1,  1])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2daccab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08b135f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "{\n",
      "V\n",
      "o\n",
      "i\n",
      "r\n",
      " \n",
      "h\n",
      "o\n",
      "m\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "365129c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4bb0750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'{' b'{' b'V' b'o' b'i' b'r' b' ' b'h' b'o' b'm' b'o' b'n' b'y' b'm'\n",
      " b'e' b's' b'|' b'T' b'o' b's' b'c' b'a' b'n' b'e' b' ' b'(' b'h' b'o'\n",
      " b'm' b'o' b'n' b'y' b'm' b'i' b'e' b')' b'}' b'}' b'\\n' b'{' b'{' b'c'\n",
      " b'o' b'o' b'r' b'd' b'|' b'4' b'3' b'.' b'5' b'|' b'1' b'1' b'.' b'2'\n",
      " b'|' b'f' b'o' b'r' b'm' b'a' b't' b'=' b'd' b'e' b'c' b'|' b'r' b'e'\n",
      " b'g' b'i' b'o' b'n' b':' b'I' b'T' b'-' b'5' b'2' b'_' b't' b'y' b'p'\n",
      " b'e' b':' b'l' b'a' b'n' b'd' b'm' b'a' b'r' b'k' b'_' b's' b'c' b'a'\n",
      " b'l' b'e' b':'], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "    print(chars_from_ids(seq)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b69fdbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{{Voir homonymes|Toscane (homonymie)}}\\n{{coord|43.5|11.2|format=dec|region:IT-52_type:landmark_scale:'\n",
      "b\"400000|display=title}}\\n{{Infobox R\\xc3\\xa9gion d'Italie\\n | nom             = Toscane\\n | blason          = Co\"\n",
      "b'at of arms of Tuscany.svg\\n | drapeau         = Flag of Tuscany.svg\\n | imageloc        = Tuscany in It'\n",
      "b'aly.svg\\n | zone            = ITE\\n | capitale        = [[Florence]]\\n | gentil\\xc3\\xa9         = Toscans / Tos'\n",
      "b'canes\\n | latitude        = 43.41\\n | longitude       = 11\\n | pr\\xc3\\xa9sident       = [[Eugenio Giani]]\\n | pa'\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "    print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "904c59d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfc40c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple\n",
    "\n",
    "split_input_target(list(\"Tensorflow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7efa1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a8cda0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b'{{Voir homonymes|Toscane (homonymie)}}\\n{{coord|43.5|11.2|format=dec|region:IT-52_type:landmark_scale'\n",
      "Target: b'{Voir homonymes|Toscane (homonymie)}}\\n{{coord|43.5|11.2|format=dec|region:IT-52_type:landmark_scale:'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57093b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c7a3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f753eded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23b7d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deeb65ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c0de22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b5fc65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6432cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46695ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05c53cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 118) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c08c9f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  30208     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  120950    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,089,462\n",
      "Trainable params: 4,089,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fa8827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "036fd9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21,  55, 113,   7,  42,  93,   8,   3,  40, 106,  98,  58, 114,\n",
       "        50,  76,  37, 116,  71,  77,  47,   3,  57, 114,  86,   3, 100,\n",
       "        46,   0,   6,  22,  29,  98,  93, 112,  41,  26,   2,  82,  59,\n",
       "       100, 117,  17,  32,   5,  59,  32,  52,  36,  55,  31,  54,  34,\n",
       "        99, 100,  38,  99,  90,  25,  40,  71,   5,   6,  77,  34, 113,\n",
       "        55,  97,  46,  22,  30,  32, 117, 117,  99, 109, 104,   0,  22,\n",
       "        32,  37,   7,  20,   1, 107, 109,  79,  90,  99,  77,  12, 100,\n",
       "         2, 117, 113,  50,  37,  84, 106,  33, 106])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db6d7812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'p://www.persee.fr/doc/befar_0257-4101_1983_mon_249_1?h=celtique&h=po |consult\\xc3\\xa9 le=31 janvier 2016 |p'\n",
      "\n",
      "Next Char Predictions:\n",
      " b\"4W\\xc5\\x99&J\\xc3\\x80'!H\\xc3\\xaf\\xc3\\xa1Z\\xcb\\x88RoE\\xe2\\x80\\x94jpO!Y\\xcb\\x88y!\\xc3\\xa7N[UNK]%5<\\xc3\\xa1\\xc3\\x80\\xc5\\x93I9 u[\\xc3\\xa7\\xe2\\x80\\x990?#[?TDW>VB\\xc3\\xa2\\xc3\\xa7F\\xc3\\xa2}8Hj#%pB\\xc5\\x99W\\xc3\\xa0N5=?\\xe2\\x80\\x99\\xe2\\x80\\x99\\xc3\\xa2\\xc3\\xbb\\xc3\\xad[UNK]5?E&3\\n\\xc3\\xb4\\xc3\\xbbr}\\xc3\\xa2p+\\xc3\\xa7 \\xe2\\x80\\x99\\xc5\\x99REw\\xc3\\xafA\\xc3\\xaf\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d07dfbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e011f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 118)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.7695274, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56873e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.86353"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc37d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee3d2af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203af72f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f71440b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ab9198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9674981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 17s 2s/step - loss: 4.8229\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 4.2448\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 16s 2s/step - loss: 3.9728\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 16s 2s/step - loss: 3.7038\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 3.5392\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 3.4101\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 3.2945\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 3.1271\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 16s 2s/step - loss: 2.9813\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 16s 2s/step - loss: 2.8624\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 16s 2s/step - loss: 2.7837\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 17s 2s/step - loss: 2.7081\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 16s 2s/step - loss: 2.6420\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 2.5821\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 2.5256\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 16s 2s/step - loss: 2.4760\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 2.4247\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 2.3730\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 16s 2s/step - loss: 2.3204\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 16s 2s/step - loss: 2.2695\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 16s 2s/step - loss: 2.2112\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 16s 2s/step - loss: 2.1509\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 17s 2s/step - loss: 2.0976\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 20s 3s/step - loss: 2.0580\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 22s 3s/step - loss: 2.0020\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 17s 2s/step - loss: 1.9398\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 1.9068\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 1.8474\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.7918\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.7336\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.6996\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.6668\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.6077\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.5816\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.5256\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.4988\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.4705\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.4141\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.3803\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.3127\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.2910\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.2549\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.2155\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.1620\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.1200\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 1.0867\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.0447\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 1.0009\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.9540\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.9190\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.8909\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.8333\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.7946\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.7663\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.7168\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.6633\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 0.6303\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 0.5906\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 17s 2s/step - loss: 0.5457\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.5063\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.4722\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 0.4432\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 0.4028\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 0.3748\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.3464\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 15s 2s/step - loss: 0.3245\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.2977\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.2775\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.2594\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.2429\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.2243\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.2080\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.1936\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.1827\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.1739\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.1594\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.1526\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.1452\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.1377\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.1316\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.1273\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.1213\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.1163\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.1130\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.1091\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.1031\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.1002\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.0955\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.0921\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.0870\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.0841\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.0819\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.0818\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.0783\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.0763\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.0734\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.0722\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.0701\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.0692\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.0674\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e36de1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "        skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            # Put a -inf at each bad index.\n",
    "            values=[-float('inf')]*len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            # Match the shape to the vocabulary\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # Convert strings to token IDs.\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # Run the model.\n",
    "        # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "        predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "        # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        # Return the characters and model state.\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2a5e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44eee79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{formatnum:16061}}\n",
      "|0,90\n",
      "|—\n",
      "|bgcolor=\"#FC2D2D\"|\n",
      "|align=left| [[Parti communiste italien (2016)|Parti communi titite (Italie)|CD]])\n",
      "|{{formatnum:47647}}\n",
      "|2,95\n",
      "|align=center| {{augmentation||8px}} 3\n",
      "|-\n",
      "|{{Infobox Parti politique italien/couleurs|PD}}|\n",
      "|34,71 ||'''22''' \n",
      "|-\n",
      "|{{Infobox Parti politique italien/couleurs|FI}}|\n",
      "|align=left|  [[Forza Italia (2013)|Forza Italia]]-[[Utalie'e comine|Vité]] fur couvrer communché tesc avec [[Itrlen]].\n",
      "Ens [[Cherre de Chanco]], [[Charles VIII d'Étaut et drépor| {{augmentation||8px}} 3\n",
      "| rowspan=\"4\" bgcolor=\"#eeeeee\" |\n",
      "|-\n",
      "|{{Infobox Parti politique italien/couleurs|Lega}}|\n",
      "|align=left|  [[Ligue du Nord|Ligue]] (Lega)\n",
      "|{{formatnum:351977}}\n",
      "|21,78\n",
      "|align=center| {{augmentation||8px}} 11,7\n",
      "| '''12'''\n",
      "|align=center| {{augmentation||8px}} 3\n",
      "|-\n",
      "|{{Infobox Parti politique italien/couleurs|PD}}|\n",
      "|align=left| [[Parti démocrate (Italie)|PD]]\n",
      "|bgcolor=\"#FFB2B2\"|33,43 ||bgcolor=\"#FFB2B2\"|2 \n",
      "|bgcolor=\"#FFB2B2\"|37,33 ||bgcolor=\"#FFB2B2\"|1 \n",
      "|bgcolor=\"#FFB2B2\"|37,35  \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 3.178400754928589\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['{'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c56a74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f97d03b5f70>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(one_step_model, 'one_step')\n",
    "one_step_reloaded = tf.saved_model.load('one_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12ec64b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:128100]] ;\n",
      "* [[Province d'Arezzo|Arezzo]] ;\n",
      "* [[Province de Sienne|Sienne]].\n",
      "}}\n",
      "\n",
      "== Culture ==\n",
      "\n",
      "La r\n"
     ]
    }
   ],
   "source": [
    "states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(100):\n",
    "    next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a6254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
